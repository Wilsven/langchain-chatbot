{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autonomous Agent\n",
    "\n",
    "This is a bare-minimal implementation of an autonomous agent that can search Arxiv for relevant papers and summarize the core ideas of the paper based on the user's research question.\n",
    "\n",
    "In this example, we will just create a highly-abstracted version, in which LangChain does all the orchestration under the hood.\n",
    "\n",
    "In the second example, we will dive deep into the details and build a similar autonomous agent from scratch without using LangChain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages & setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain\n",
    "# %pip install arxiv\n",
    "# %pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A high-level abstracted example using LangChain\n",
    "\n",
    "This section is a very high level example of how to define an agent using LangChain.\n",
    "\n",
    "* We first define the tool that the language model can use: arxiv api, including the name and descriptions for the tool, so that the\n",
    "LLM knows it can use the tool when needed\n",
    "* We then initialize the agent by passing it the tools and the LLM model\n",
    "* Finally, we ask the agent a question. The agent will use the ReAct (Reason + Act) framework to complete the task. It first thinks if it has all the\n",
    "information needed, then decides to use the arxiv API to search for relevant papers, when it gets the papers, it will summarize the\n",
    "content and give them back to the user."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0) # Initialize the LLM to be used\n",
    "\n",
    "description = \"\"\"\n",
    "Search on arxiv. The tool can search a keyword on arxiv for the top papers. \n",
    "It will return publishing date, title, authors, and summary of the papers.\n",
    "\"\"\"\n",
    "\n",
    "arxiv = ArxivAPIWrapper()\n",
    "arxiv_tool = Tool(\n",
    "    name=\"arxiv_search\",\n",
    "    description=description,\n",
    "    func=arxiv.run\n",
    ")\n",
    "\n",
    "tools = [arxiv_tool]\n",
    "\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_chain.run(\"What is ReAct reasoning and acting in language models?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an autonomous agent from scratch\n",
    "\n",
    "In this example, we will create an autonomous agent from scratch. The goal of this part is for you to understand how the components of autonomous agents work, instead of showing the best implementation for production. For production purposes, I recommend using pre-packages frameworks like LangChain to get the job done faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import arxiv\n",
    "\n",
    "# Set up the OpenAI API\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "def getResponse(prompt):\n",
    "    \"\"\"\n",
    "    Wrap the OpenAI API call in this function.\n",
    "    \"\"\" \n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature = 0, # We want consistent behavior, so we set a very low temperature\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You're a helpful assistant. Carefully follow the user's instructions.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    response = str(response['choices'][0]['message']['content'])\n",
    "    return response\n",
    "\n",
    "\n",
    "def parseResponse(response, memory,tools):\n",
    "    \"\"\"\n",
    "    Parse the response from GPT to determine if the objective is finished.\n",
    "    If it is finished, just give the final answer.\n",
    "    If the objective cannot be finished with the context and tools, it will say it cannot answer\n",
    "    If GPT picks a tool, execute the tool and save the result of the tool in memory.\n",
    "    \"\"\"\n",
    "    finished = False\n",
    "\n",
    "    if response.startswith('FINAL ANSWER:'):\n",
    "        finished = True\n",
    "        memory.append(response)\n",
    "        return (finished, response, memory)\n",
    "    elif response == 'FINAL: CANNOT ANSWER':\n",
    "        finished = True\n",
    "        memory.append(response)\n",
    "        return (finished, response, memory)\n",
    "    elif response.startswith('USE '):\n",
    "        # split the string using ':' as the delimiter\n",
    "        parsed_str = response.split(':')\n",
    "\n",
    "        # get the tool name and parameter\n",
    "        tool_name = parsed_str[0].split()[1]\n",
    "        parameter = parsed_str[1]\n",
    "\n",
    "        print(\"THOUGHT: \" + response)\n",
    "        memory.append(\"THOUGHT: \" + response)\n",
    "\n",
    "        result = executeTool(tool_name, parameter,tools)\n",
    "\n",
    "        new_memory = \"OBSERVATION: \" + str(result)\n",
    "        print(new_memory)\n",
    "        memory.append(new_memory)\n",
    "\n",
    "        return (finished, result, memory)\n",
    "    \n",
    "\n",
    "def executeTool(tool_name, parameter,tools):\n",
    "    \"\"\"\n",
    "    Execute the tool that GPT picks using the parameter it gives.\n",
    "    Returns the execution result so that GPT can have the relevant info.\n",
    "    \"\"\"\n",
    "    # Find the tool with the given name\n",
    "    tool = None\n",
    "    for t in tools:\n",
    "        if t['tool_name'] == tool_name:\n",
    "            tool = t\n",
    "            break\n",
    "    \n",
    "    # If the tool is found, execute its function with the given parameter\n",
    "    if tool:\n",
    "        return tool['function_name'](parameter)\n",
    "    else:\n",
    "        return \"Tool not found\"\n",
    "    \n",
    "    \n",
    "def determineAction(objective, memory, tools):\n",
    "    \"\"\"\n",
    "    Use GPT to determine the action to take by giving it the objective, memory, and tools.\n",
    "    If it think it has finished the objective, just give the answer.\n",
    "    If it needs more info, it will pick the tool to get the relevant information based on the tool description.\n",
    "    \"\"\"\n",
    "    formattedPrompt = f\"\"\"Determine if the following memory is enough to answer\\n\n",
    "    the user's objective. Your past actions are stored in the memory for reference\\n\n",
    "    If it is enough, answer the question in the format: 'FINAL ANSWER: '. \\n\n",
    "    If the memory is not enough, you can use a tool in the available tools section\\n\n",
    "    to get more information. When using a tool you should use this format: \\n\n",
    "    'USE :'. If no tool can help you achieve the user's \\n\n",
    "    objective, then answer 'FINAL: CANNOT ANSWER'.\n",
    "\n",
    "    ```Objective\n",
    "    Answer: {objective}\n",
    "    ```\n",
    "\n",
    "    ```Memory\n",
    "    {memory}\n",
    "    ```\n",
    "\n",
    "    ```Available Tools\n",
    "    {tools}\n",
    "    ```\n",
    "\n",
    "    \"\"\"\n",
    "    response = getResponse(formattedPrompt)\n",
    "    (finished, result, memory) = parseResponse(response, memory,tools)\n",
    "    return (finished, result, memory)\n",
    "\n",
    "\n",
    "def searchArxiv(keyword):\n",
    "    \"\"\"\n",
    "    Wrap the search arxiv function as a tool for GPT\n",
    "    Input is a search keyword\n",
    "    Output is a list of dictionaries with title, published date, authors, and summary of papers\n",
    "    \"\"\"\n",
    "    # Perform a search with the given query\n",
    "    search = arxiv.Search(query=keyword, max_results=3)\n",
    "    \n",
    "    # Get the metadata for each result and extract relevant information\n",
    "    results = []\n",
    "    for result in search.results():\n",
    "        title = result.title\n",
    "        published_date = result.published.strftime(\"%Y-%m-%d\")\n",
    "        authors = \", \".join(author.name for author in result.authors)\n",
    "        summary = result.summary\n",
    "        \n",
    "        # Store the extracted information as a dictionary\n",
    "        results.append((\n",
    "            \"title: \" + title,\n",
    "            \"published_date: \" + published_date,\n",
    "            \"authors: \" + authors,\n",
    "            \"summary: \" + summary\n",
    "        ))\n",
    "    \n",
    "    # Return the list of tuples containing the result information\n",
    "    return results\n",
    "\n",
    "\n",
    "def startAgent():\n",
    "    \"\"\"\n",
    "    Initialize memory, tools for the GPT agent.\n",
    "    Ask for a user objective and let it run iteratively untill the objective is achieved.\n",
    "    As a safety measure, it will also stop after 5 iterations just in case things go wrong.\n",
    "    \"\"\"\n",
    "    objective = input(\"What is your research question? \")\n",
    "    # For simplicity, we will just use a list to store every thing. \n",
    "    # For production, you will probably use vector databases.\n",
    "    memory = []\n",
    "\n",
    "    tools = [{'tool_name': 'searchArxiv', \n",
    "            'description': \"\"\"You can use this tool to search for scientific papers on Arxiv. The response will have title, author, published date, and summary.\"\"\", \n",
    "            'function_name' : searchArxiv,\n",
    "            'parameter': 'search key word'}]\n",
    "    \n",
    "    n = 0\n",
    "    while True:\n",
    "        (finished, result, memory) = determineAction(objective, memory, tools)\n",
    "        n += 1\n",
    "\n",
    "        if finished:\n",
    "            print(result)\n",
    "            return\n",
    "        \n",
    "        if n > 5:\n",
    "            print(\"Ended for reaching limit.\")\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startAgent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
