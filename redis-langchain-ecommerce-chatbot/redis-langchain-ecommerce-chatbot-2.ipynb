{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Redis LangChain OpenAI eCommerce Chatbot](https://lablab.ai/t/redis-langchain-ecommerce-chatbot) (lablab.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from redis.commands.search.field import VectorField\n",
    "from redis.commands.search.field import TextField\n",
    "from redis.commands.search.field import TagField\n",
    "from redis.commands.search.query import Query\n",
    "import redis\n",
    "\n",
    "\n",
    "redis_conn = redis.Redis(\n",
    "    host=\"redis-18975.c300.eu-central-1-1.ec2.cloud.redislabs.com\",\n",
    "    port=18975,\n",
    "    password=\"xxxxxxxxxxx\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TEXT_LENGTH = 512\n",
    "NUMBER_PRODUCTS = 1000\n",
    "\n",
    "\n",
    "def auto_truncate(val):\n",
    "    return val[:MAX_TEXT_LENGTH]\n",
    "\n",
    "\n",
    "# Load Product data and truncate long text fields\n",
    "all_prods_df = pd.read_csv(\n",
    "    \"product_data.csv\",\n",
    "    converters={\n",
    "        \"bullet_point\": auto_truncate,\n",
    "        \"item_keywords\": auto_truncate,\n",
    "        \"item_name\": auto_truncate,\n",
    "    },\n",
    ")\n",
    "all_prods_df[\"primary_key\"] = (\n",
    "    all_prods_df[\"item_id\"] + \"-\" + all_prods_df[\"domain_name\"]\n",
    ")\n",
    "all_prods_df[\"item_keywords\"].replace(\"\", np.nan, inplace=True)\n",
    "all_prods_df.dropna(subset=[\"item_keywords\"], inplace=True)\n",
    "all_prods_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# get the first 1000 products with non-empty item keywords\n",
    "product_metadata = all_prods_df.head(NUMBER_PRODUCTS).to_dict(orient=\"index\")\n",
    "\n",
    "all_prods_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-distilroberta-v1\")\n",
    "\n",
    "\n",
    "item_keywords = [product_metadata[i][\"item_keywords\"] for i in product_metadata.keys()]\n",
    "item_keywords_vectors = [model.encode(sentence) for sentence in item_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_keywords_vectors)\n",
    "len(product_metadata)\n",
    "\n",
    "# Check one of the products\n",
    "product_metadata[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Redis Index and Loading Vectors\n",
    "\n",
    "Create a function to load vectors into the Redis index and a function to create a flat index. We will use these functions later to index our product data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(client, product_metadata, vector_dict, vector_field_name):\n",
    "    p = client.pipeline(transaction=False)\n",
    "    for index in product_metadata.keys():\n",
    "        # hash key\n",
    "        key = \"product:\" + str(index) + \":\" + product_metadata[index][\"primary_key\"]\n",
    "\n",
    "        # hash values\n",
    "        item_metadata = product_metadata[index]\n",
    "        item_keywords_vector = vector_dict[index].astype(np.float32).tobytes()\n",
    "        item_metadata[vector_field_name] = item_keywords_vector\n",
    "\n",
    "        # HSET\n",
    "        p.hset(key, mapping=item_metadata)\n",
    "\n",
    "    p.execute()\n",
    "\n",
    "\n",
    "def create_flat_index(\n",
    "    redis_conn,\n",
    "    vector_field_name,\n",
    "    number_of_vectors,\n",
    "    vector_dimensions=512,\n",
    "    distance_metric=\"L2\",\n",
    "):\n",
    "    redis_conn.ft().create_index(\n",
    "        [\n",
    "            VectorField(\n",
    "                vector_field_name,\n",
    "                \"FLAT\",\n",
    "                {\n",
    "                    \"TYPE\": \"FLOAT32\",\n",
    "                    \"DIM\": vector_dimensions,\n",
    "                    \"DISTANCE_METRIC\": distance_metric,\n",
    "                    \"INITIAL_CAP\": number_of_vectors,\n",
    "                    \"BLOCK_SIZE\": number_of_vectors,\n",
    "                },\n",
    "            ),\n",
    "            TagField(\"product_type\"),\n",
    "            TextField(\"item_name\"),\n",
    "            TextField(\"item_keywords\"),\n",
    "            TagField(\"country\"),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to our Redis DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_KEYWORD_EMBEDDING_FIELD = \"item_keyword_vector\"\n",
    "TEXT_EMBEDDING_DIMENSION = 768\n",
    "NUMBER_PRODUCTS = 1000\n",
    "\n",
    "print(\"Loading and Indexing + \" + str(NUMBER_PRODUCTS) + \" products\")\n",
    "\n",
    "# flush all data\n",
    "redis_conn.flushall()\n",
    "\n",
    "# create flat index & load vectors\n",
    "create_flat_index(\n",
    "    redis_conn,\n",
    "    ITEM_KEYWORD_EMBEDDING_FIELD,\n",
    "    NUMBER_PRODUCTS,\n",
    "    TEXT_EMBEDDING_DIMENSION,\n",
    "    \"COSINE\",\n",
    ")\n",
    "load_vectors(\n",
    "    redis_conn, product_metadata, item_keywords_vectors, ITEM_KEYWORD_EMBEDDING_FIELD\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Chatbot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go from user input string to product keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# loads .env file with your OPENAI_API_KEY\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "\n",
    "# Define embedding model\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3, openai_api_key=OPENAI_API_KEY)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product_description\"],\n",
    "    template=\"Create comma seperated product keywords to perform a query on a amazon dataset for this user input: {product_description}\",\n",
    ")\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userinput = input(\"Hey im a E-commerce Chatbot, how can i help you today? \")\n",
    "print(\"User:\", userinput)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "keywords = chain.run(userinput)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query our data\n",
    "\n",
    "Use the generated keywords to query the product embeddings in Redis and retrieve the top 3 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "# Vectorize the query\n",
    "query_vector = model.encode(keywords).astype(np.float32).tobytes()\n",
    "\n",
    "# Prepare the query\n",
    "q = (\n",
    "    Query(\n",
    "        f\"*=>[KNN {top_k} @{ITEM_KEYWORD_EMBEDDING_FIELD} $vec_param AS vector_score]\"\n",
    "    )\n",
    "    .sort_by(\"vector_score\")\n",
    "    .paging(0, top_k)\n",
    "    .return_fields(\"vector_score\", \"item_name\", \"item_id\", \"item_keywords\")\n",
    "    .dialect(2)\n",
    ")\n",
    "params_dict = {\"vec_param\": query_vector}\n",
    "\n",
    "# Execute the query\n",
    "results = redis_conn.ft().search(q, query_params=params_dict)\n",
    "\n",
    "full_result_string = \"\"\n",
    "for product in results.docs:\n",
    "    full_result_string += (\n",
    "        product.item_name\n",
    "        + \" \"\n",
    "        + product.item_keywords\n",
    "        + \" \"\n",
    "        + product.item_id\n",
    "        + \"\\n\\n\\n\"\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "\n",
    "template = \"\"\"You are a chatbot. Be kind, detailed and nice. Present the given queried search result in a nice way as answer to the user input. dont ask questions back! just take the given context\n",
    "\n",
    "{chat_history}\n",
    "Human: {user_msg}\n",
    "Chatbot:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"chat_history\", \"user_msg\"], template=template)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "llm_chain = LLMChain(\n",
    "    llm=OpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\", temperature=0.8, openai_api_key=OPENAI_API_KEY\n",
    "    ),\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "answer = llm_chain.predict(user_msg=f\"{full_result_string} ---\\n\\n {userinput}\")\n",
    "print(\"Bot:\", answer)\n",
    "time.sleep(0.5)\n",
    "\n",
    "while True:\n",
    "    follow_up = input(\"Anything else you want to ask about this topic?\")\n",
    "    print(\"User:\", follow_up)\n",
    "    answer = llm_chain.predict(user_msg=follow_up)\n",
    "    print(\"Bot:\", answer)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
